<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>卷积神经网络 CNN</title>
      <link href="/2022/04/25/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"/>
      <url>/2022/04/25/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/</url>
      
        <content type="html"><![CDATA[<h1 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络 CNN"></a>卷积神经网络 CNN</h1><p>Convolutional Neural Network——designed for image</p><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><p>一张图片有三维的tensor（可以理解为大于2的矩阵），一个维度是长，一个维度是宽，一个维度是channels。长和宽代表着图片的解析度，像素点的个数；channels=3就是RGB，=1就是灰度图像。我们把图片拉直成向量，就可以作为一个neural的输入，这个向量每一维的数值就代表这个像素颜色的强度。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220125113646601.png" alt="image-20220125113646601"></p><h2 id="卷积处理"><a href="#卷积处理" class="headerlink" title="卷积处理"></a>卷积处理</h2><p>假设我们用1000个神经元直接进行训练，需要3*10^7个参数。对于我们来说参数越多，模型的弹性越大，越会有overfitting的风险。为了避免使用这么多的参数，同时考虑到影像辨识的目的，我们希望模型能够根据一定特征的patterns来做识别，比如鸟嘴、鸟的眼睛，图片的其他部分就不需要作为神经的输入，不需要fully connected。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220125113938251.png" alt="image-20220125113938251"></p><p>convolution就是用不同的filter来识别patterns。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220125121007441.png" alt="image-20220125121007441"></p><p>stride:步长；        </p><p>padding:填充；        </p><p>feature map:图片通过一个卷积层之后得到的新的特征图片，它的channels=上一个卷积层filters的个数。下一卷积层中filter的高度就是图片的channels。</p><p>每一个filter矩阵中的元素对应了神经元共用的参数，让一个卷积核扫过整张图片（卷积，让不同的receptive field 可以共用参数），这样就降低了弹性，避免过拟合问题。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220125122147730.png" alt="image-20220125122147730"></p><h2 id="池化-Pooling"><a href="#池化-Pooling" class="headerlink" title="池化 Pooling"></a>池化 Pooling</h2><p>我们发现对大的图片进行抽样后，依旧保持图像特征。做完convolution后，可以进行pooling，把图片变小（channels不变），减少运算量。池化的filter进行运算之后，选择只保留一定区域里的代表（比如max）。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220125125630182.png" alt="image-20220125125630182"></p><p>但如果对于特别精细的特征识别，就不做pooling。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>应用层</title>
      <link href="/2022/04/21/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/2.%E5%BA%94%E7%94%A8%E5%B1%82/"/>
      <url>/2022/04/21/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/2.%E5%BA%94%E7%94%A8%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机网络——自顶向下"><a href="#计算机网络——自顶向下" class="headerlink" title="计算机网络——自顶向下"></a>计算机网络——自顶向下</h1><h2 id="2-应用层"><a href="#2-应用层" class="headerlink" title="2 应用层"></a>2 应用层</h2><h3 id="2-1-应用层协议原理"><a href="#2-1-应用层协议原理" class="headerlink" title="2.1 应用层协议原理"></a>2.1 应用层协议原理</h3><h4 id="2-1-1-网络应用程序体系结构"><a href="#2-1-1-网络应用程序体系结构" class="headerlink" title="2.1.1 网络应用程序体系结构"></a>2.1.1 网络应用程序体系结构</h4><p><strong>客户机/服务器</strong>：<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408115155480.png" alt="image-20220408115155480"></p><p>例：web、FTP、e-main</p><p><strong>对等P2P</strong>：<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408115220496.png" alt="image-20220408115220496"></p><p>例：Gnurella、迅雷</p><p><strong>混合模式</strong></p><h4 id="2-1-2-进程通信"><a href="#2-1-2-进程通信" class="headerlink" title="2.1.2 进程通信"></a>2.1.2 进程通信</h4><p>同一主机中，使用IPC（操作系统定义）通信。</p><p>不同主机中，进城process通过交换报文messgae进行通信。</p><p><strong>客户和服务器进程</strong>：客户机发起通信，服务器等待联系。P2P体系的应用进城具有双重特性。</p><p><strong>进程的接口</strong>：套接字，是应用层与运输层之间的接口。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408115956927.png" alt="image-20220408115956927"></p><p><strong>进程寻址</strong>：主机IP地址+进程端口号。</p><h4 id="2-1-3-可供应用程序使用的传输服务"><a href="#2-1-3-可供应用程序使用的传输服务" class="headerlink" title="2.1.3 可供应用程序使用的传输服务"></a>2.1.3 可供应用程序使用的传输服务</h4><p><strong>可靠数据传输</strong>：是否容忍丢失。</p><p><strong>吞吐量</strong>：传送比特的速率。不同应用对带宽的限制。</p><p><strong>定时</strong>：就是延时。</p><p><strong>安全</strong>。</p><h3 id="2-2-Web应用和HTTP协议"><a href="#2-2-Web应用和HTTP协议" class="headerlink" title="2.2 Web应用和HTTP协议"></a>2.2 Web应用和HTTP协议</h3><p>Web的应用层协议是HTTP，超文本传输协议。</p><h4 id="2-2-1-HTTP概况"><a href="#2-2-1-HTTP概况" class="headerlink" title="2.2.1 HTTP概况"></a>2.2.1 HTTP概况</h4><p>HTTP由客户机程序和服务器程序实现，通过交换HTTP报文进行会话。</p><p>Web页面由对象（HTML文件、JPG图片等）组成，每个对象由URL(( Uniform Resource Locator)进行寻址。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408120725355.png" alt="image-20220408120725355"></p><p>HTTP是一个无状态协议，因为服务器并不保存关于客户的任何信息。</p><h4 id="2-2-2-非持续连接和持续连接"><a href="#2-2-2-非持续连接和持续连接" class="headerlink" title="2.2.2 非持续连接和持续连接"></a>2.2.2 非持续连接和持续连接</h4><p><strong>非持续连接</strong>(Version=1.0)：TCP每发送一个对象后就关闭。</p><p>1.客户进程在80端口号（默认）发起向客户机<a href="http://www.swust.edu.cn的tcp连接;/">www.swust.edu.cn的TCP连接；</a></p><p>2.客户经过它的套接字向服务器发送请求报文；</p><p>3.服务器经过它的套接字接收请求报文，检索出对象<a href="http://www.swust.edu.cn/someDept/pic.gif%E5%B9%B6%E5%B0%81%E8%A3%85%E5%88%B0%E6%8A%A5%E6%96%87%E4%B8%AD%EF%BC%8C%E5%86%8D%E9%80%9A%E8%BF%87%E5%A5%97%E6%8E%A5%E5%AD%97%E5%90%91%E5%AE%A2%E6%88%B7%E5%8F%91%E9%80%81%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%EF%BC%9B">www.swust.edu.cn/someDept/pic.gif并封装到报文中，再通过套接字向客户发送响应报文；</a></p><p>4.服务器进程断开TCP连接；</p><p>5.客户收到响应报文，连接关闭；</p><p>6.重复上述步骤引用其他对象。</p><p><strong>总响应时间：</strong>2个RTT+服务器传输时间。原因：TCP三次握手的前两个部分占用1个RTT，客户机结合握手的第三个部分向TCP发送一个HTTP请求报文，然后服务器响应，这用去了另一个RTT。</p><p><strong>缺点</strong>：串行访问时间长；并行访问占用资源多(分配的TCP缓冲区和TCP变量)。</p><p><strong>持续连接</strong>(Version=1.11)：TCP为相同的客户-服务器间的请求和响应持续打开。</p><h4 id="2-2-3-HTTP报文格式"><a href="#2-2-3-HTTP报文格式" class="headerlink" title="2.2.3 HTTP报文格式"></a>2.2.3 HTTP报文格式</h4><p><strong>请求报文</strong>:第一行为请求行（方法method+URL+HTTP版本)，后继行为首部行，最后是实体。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408123221263.png" alt="image-20220408123221263"></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408123347554.png" alt="image-20220408123347554"></p><p>method方法类型有:GET（请求访问，实体为空）、POST、HEAD、PUT、DELETE。</p><p><strong>响应报文</strong>：第一行为状态行（HTTP版本+状态码+短语phrase)，后继行为首部行，最后是实体。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408133759610.png" alt="image-20220408133759610"></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408133811897.png" alt="image-20220408133811897"></p><p>常见的状态码和短语：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">200</span> <span class="variable constant_">OK</span></span><br><span class="line"><span class="comment">//请求成功，请求的对象在这个报文后面</span></span><br><span class="line"><span class="number">301</span> <span class="title class_">Moved</span> <span class="title class_">Permanently</span></span><br><span class="line"><span class="comment">//请求的对象已转移，新的URL在响应报文的Location:首部行中指定</span></span><br><span class="line"><span class="number">400</span> <span class="title class_">Bad</span> <span class="title class_">Request</span></span><br><span class="line"><span class="comment">//请求报文不为服务器理解</span></span><br><span class="line"><span class="number">404</span> <span class="title class_">Not</span> <span class="title class_">Found</span></span><br><span class="line"><span class="comment">//请求的文档没有在该服务器上发现</span></span><br><span class="line"><span class="number">505</span> <span class="variable constant_">HTTP</span> <span class="title class_">Version</span> <span class="title class_">Not</span> <span class="title class_">Supported</span></span><br></pre></td></tr></table></figure><h4 id="2-2-4-用户与服务器的交互：Cookie"><a href="#2-2-4-用户与服务器的交互：Cookie" class="headerlink" title="2.2.4 用户与服务器的交互：Cookie"></a>2.2.4 用户与服务器的交互：Cookie</h4><p>无状态的HTTP简化了服务器的设计，但不能保存用户信息。所以HTTP使用Cookie对用户进行跟踪。</p><p><strong>cookie组件</strong>包括：HTTP响应报文中的cookie首部行；请求报文中的cookie首部行；用户主机保留的cookie文件；Web站点的后端数据库。</p><p>用户每请求一个Web页面，浏览器会从cookie文件中获取对这个网站的识别码，放到HTTP请求报文中的包括识别码的cookie首部行中。cookie首部用来标识一个用户。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408134647714.png" alt="image-20220408134647714"></p><h4 id="2-2-5-Web缓存"><a href="#2-2-5-Web缓存" class="headerlink" title="2.2.5 Web缓存"></a>2.2.5 Web缓存</h4><p><strong>Web缓存器</strong>：保存最近请求的web对象。浏览器向缓存发送所有HTTP请求，若对象在缓存中：缓存返回对象；否则缓存向起始服务器请求对象，然后向客户机返回对象。</p><p>好处：1）减小客户机请求的响应时间；2）减少机构内部网与因特网接入链路的通信量。</p><h4 id="2-2-6-条件GET方法"><a href="#2-2-6-条件GET方法" class="headerlink" title="2.2.6 条件GET方法"></a>2.2.6 条件GET方法</h4><p>为解决缓存中对象始终最新的问题，用<strong>条件GET</strong>方法：缓存器在HTTP请求中包含一个“If-modified-since: <date>”，指定缓存版本的日期，服务器判断如果缓存的拷贝是最新，就响应不包含对象: </p><p>“HTTP/1.0 304 Not Modified”，否则修改对象。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408135709719.png" alt="image-20220408135709719"></p><h3 id="2-3-文件传输协议：FTP"><a href="#2-3-文件传输协议：FTP" class="headerlink" title="2.3 文件传输协议：FTP"></a>2.3 文件传输协议：FTP</h3><p><strong>特点</strong>：使用双TCP连接，一个<strong>控制连接</strong>(端口21)，一个<strong>数据连接</strong>(端口20)。</p><p><strong>控制连接</strong>用于在两台主机传输控制信息，如用户标识、口令、控制命令等，<strong>数据连接</strong>用于实际发送文件。</p><p>FTP使用独立的控制连接，我们称FTP是<strong>带外控制</strong>；而HTTP是带内控制。</p><h3 id="2-4-电子邮件"><a href="#2-4-电子邮件" class="headerlink" title="2.4  电子邮件"></a>2.4  电子邮件</h3><p>电子邮件系统组成：用户代理(阅读器，如Outlook,Foxmail)、邮件服务器、简单邮件<strong>传输</strong>协议: SMTP。</p><p>从发送方的用户代理开始，传输到发送方的邮件服务器，再传输到接收方的邮件服务器，最后被分发到接收方的邮箱中。</p><h4 id="2-4-1-SMTP"><a href="#2-4-1-SMTP" class="headerlink" title="2.4.1 SMTP"></a>2.4.1 SMTP</h4><p>报文格式：7bitASCII。</p><p>端口号：25。</p><p>使用TCP连接。传输阶段有握手、传输、关闭。</p><h4 id="2-4-4-邮件访问协议"><a href="#2-4-4-邮件访问协议" class="headerlink" title="2.4.4 邮件访问协议"></a>2.4.4 邮件访问协议</h4><p>POP3邮局协议</p><p>IMAP4因特网邮件访问协议</p><p>基于Web的电子邮件：用户代理就是浏览器，使用HTTP与其他远程邮箱进行通信。但邮件服务器和其他服务器间仍使用SMTP。 </p><h3 id="2-5-DNS"><a href="#2-5-DNS" class="headerlink" title="2.5 DNS"></a>2.5 DNS</h3><p>Domain Name Server域名服务器。</p><p>使用UDP。</p><p>例：主机名为<a href="http://www.swust.edu.cn,ip地址/">www.swust.edu.cn，IP地址</a>(32 bit) 为220.166.52.4，DNS完成主机名到IP地址的解析。</p><h4 id="2-5-1-分布式、等级制数据库"><a href="#2-5-1-分布式、等级制数据库" class="headerlink" title="2.5.1 分布式、等级制数据库"></a>2.5.1 分布式、等级制数据库</h4><h4 id=""><a href="#" class="headerlink" title=""></a><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408141738936.png" alt="image-20220408141738936"></h4><h4 id="2-5-2两种查询方式"><a href="#2-5-2两种查询方式" class="headerlink" title="2.5.2两种查询方式"></a>2.5.2两种查询方式</h4><p><strong>迭代查询</strong>：我的理解是，去去就回。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408142004722.png" alt="image-20220408142004722"></p><p><strong>递归查询</strong>：我的理解是，先去后回。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220408142036974.png" alt="image-20220408142036974"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习服务器平台简单手册——AutoDL</title>
      <link href="/2022/03/22/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E2%80%94%E2%80%94AutoDL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
      <url>/2022/03/22/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E2%80%94%E2%80%94AutoDL%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习平台——AutoDL"><a href="#深度学习平台——AutoDL" class="headerlink" title="深度学习平台——AutoDL"></a>深度学习平台——AutoDL</h1><p>无意中在B站看到了有人推荐AutoDL这个网站，我去看了一下AutoDL平台的价格也很吸引人，而且还有学生优惠，所以先试着用它来跑代码。</p><p>AutoDL主页：<a href="https://www.autodl.com/home">https://www.autodl.com/home</a></p><h2 id="1-注册"><a href="#1-注册" class="headerlink" title="1.注册"></a>1.注册</h2><p>新用户注册后会赠送代金券。注册之后可以使用教育邮箱（我用的就是湖大的@hun.edu.cn的邮箱)验证来进行学生认证，获得折扣。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222182232303.png" alt="image-20220222182232303"></p><h2 id="2-创建实例"><a href="#2-创建实例" class="headerlink" title="2. 创建实例"></a>2. 创建实例</h2><p>点击右上角控制台，进入我的实例，可以租用新实例。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222182340678.png" alt="image-20220222182340678"></p><p>有四个区的多种主机可以选择。选择的时候除了关注型号外，还要注意硬盘的容量、是否可以后期扩充等。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222182525215.png" alt="image-20220222182525215"></p><p>创建后根据需要的库版本选择镜像。</p><h2 id="3-传输文件"><a href="#3-传输文件" class="headerlink" title="3. 传输文件"></a>3. 传输文件</h2><p>要跑代码的第一个任务就是把代码工程上传到网站平台上。在平时我一般使用pycharm和vs code进行代码编译，但是pycharm的社区板不支持远程编程，专业版又需要付费，所以这里选择使用vs code。</p><p>在扩展中搜索Remote-SSH并安装（以下图片来自网站的帮助文档）。</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916200211959.png" alt="image-20210916200211959"></p><p>安装后添加刚才申请成功的登录信息：主机ID和密码。</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916195423472.png" alt="image-20210916195423472"></p><p>在vs code中连接主机并依据提示输入ID和密码。</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916200538203.png" alt="image-20210916200538203"></p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916200742778.png" alt="image-20210916200742778"></p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916201832127.png" alt="image-20210916201832127"></p><p>弹窗提示配置配置文件，不需要修改的话可以回车选择默认路径。</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20220120120528330.png" alt="image-20220120120528330"></p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916202041401.png" alt="image-20210916202041401"></p><p>这时会额外打开一个vs code的窗口，根据提示输入密码。</p><p><img src="https://www.autodl.com/docs/vscode.assets/image-20210916202253038.png" alt="image-20210916202253038"></p><p>此时注意到左下角有主机ID的标示，说明连接成功。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222183516989.png" alt="image-20220222183516989"></p><p>下载**<a href="https://www.autodl.com/docs/filezilla/">FileZilla</a>软件**（客户端版）进行上传数据。安装后打开文件-&gt;站点管理器-&gt;新站点，选择SFTP协议，填入主机ID和端口号（在SSH登录信息处可以看到，如ssh -p 29154 <a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#114;&#101;&#x67;&#105;&#111;&#110;&#45;&#49;&#x31;&#x2e;&#97;&#117;&#116;&#111;&#100;&#108;&#x2e;&#99;&#x6f;&#109;">&#x72;&#111;&#x6f;&#116;&#64;&#114;&#101;&#x67;&#105;&#111;&#110;&#45;&#49;&#x31;&#x2e;&#97;&#117;&#116;&#111;&#100;&#108;&#x2e;&#99;&#x6f;&#109;</a> ，主机就是region-11.autodl.com ，端口为29154），用户root，输入密码，点击连接。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222183848018.png" alt="image-20220222183848018"></p><p>连接（图示为未连接）成功后左侧为本机的文件路径，右侧为远程主机的文件路径，将左侧文件直接拖入右侧路径即可。</p><p><img src="https://www.autodl.com/docs/filezilla.assets/image-20211109112833891.png" alt="image-20211109112833891"></p><p>然后在vs code中按远程主机路径打开项目即可进行远程调试。</p><h2 id="4-公开数据集"><a href="#4-公开数据集" class="headerlink" title="4. 公开数据集"></a>4. 公开数据集</h2><p>同样可以采用第三条的方法传输数据集，但网站还有几个常用公开数据集，可以直接使用。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220222184508596.png" alt="image-20220222184508596"></p><p>复制路径后就可以在项目中进行学习了。</p><h2 id="5-我的镜像"><a href="#5-我的镜像" class="headerlink" title="5. 我的镜像"></a>5. 我的镜像</h2><p>实例运行结束后，可以把当前配置保存为镜像，在下一次需要的时候使用镜像配置就可以了。详细参考网站的帮助文档。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络概述</title>
      <link href="/2022/02/15/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/"/>
      <url>/2022/02/15/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/1.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机网络概述"><a href="#计算机网络概述" class="headerlink" title="计算机网络概述"></a>计算机网络概述</h1><h2 id="1-1-什么是Internet"><a href="#1-1-什么是Internet" class="headerlink" title="1.1 什么是Internet"></a>1.1 什么是Internet</h2><p>网络：结点和边</p><p>计算机网络：</p><p>（1）结点（端系统（主机）结点：手机、pad、电脑……和上面运行的网络应用程序；数据交换结点：路由器、交换机）</p><p>（2）边：通信链路（接入网链路：主机连接到互联网的链路；主干链路：路由器间的链路）</p><p>（3）协议：标准。协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及在报文传输和接受或其他事件方面所采取的动作。</p><h2 id="1-2-网络边缘"><a href="#1-2-网络边缘" class="headerlink" title="1.2 网络边缘"></a>1.2 网络边缘</h2><p>按组成类型将互联网的网络结构分成</p><p>网络边缘edge：主机、应用程序；</p><p>网络核心core：路由器、网络的网络；</p><p>网络接入access：连接edge和core的通信链路；</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220204153616869.png" alt="image-20220204153616869"></p><p>边缘通过接入连接核心，从而使任意两个端系统之间可以相互通信。网络核心起着数据交换的作用。 </p><h3 id="1、两种模式"><a href="#1、两种模式" class="headerlink" title="1、两种模式"></a>1、两种模式</h3><h4 id="（1）C-S-客户端-服务器模式"><a href="#（1）C-S-客户端-服务器模式" class="headerlink" title="（1）C/S  客户端/服务器模式"></a>（1）C/S  客户端/服务器模式</h4><p>客户端向服务器请求、接收服务，服务器为主，客户端为从。</p><p>存在可扩充性差的问题，比如客户端请求多了就会不响应。</p><h4 id="（2）对等peer-peer模式"><a href="#（2）对等peer-peer模式" class="headerlink" title="（2）对等peer-peer模式"></a>（2）对等peer-peer模式</h4><p>例如迅雷等分布式的文件分发系统。请求多，相应的结点也多。</p><h3 id="2-、通信方式"><a href="#2-、通信方式" class="headerlink" title="2 、通信方式"></a>2 、通信方式</h3><h4 id="（1）面向连接的通信方式"><a href="#（1）面向连接的通信方式" class="headerlink" title="（1）面向连接的通信方式"></a>（1）面向连接的通信方式</h4><p>在端系统之间传输数据，传输之前先握手做好准备，建立连接。</p><p>TCP服务（可靠性、流量控制、拥塞控制）。</p><h4 id="（2）无连接的服务"><a href="#（2）无连接的服务" class="headerlink" title="（2）无连接的服务"></a>（2）无连接的服务</h4><p>UDP:不打招呼，很简单。</p><p>如实时聊天。</p><h2 id="1-3-网络核心"><a href="#1-3-网络核心" class="headerlink" title="1.3 网络核心"></a>1.3 网络核心</h2><p>路由器的网状网络</p><p><strong>怎样通过网络进行数据传输</strong></p><h4 id="（1）电路交换"><a href="#（1）电路交换" class="headerlink" title="（1）电路交换"></a>（1）电路交换</h4><p>将网络资源分成片，为呼叫分配片。为每个呼叫预留一条专有电路。如传统电话网络。</p><p>不适合计算机之间的通信。</p><h4 id="（2）分组交换"><a href="#（2）分组交换" class="headerlink" title="（2）分组交换"></a>（2）分组交换</h4><p>将传送的数据分成组，以分组packet为单位存储-转发。</p><p>存储-转发：被传输到下一个链路之前，整个分组必须到达路由器。 </p><p>排队和延迟：到达速率&gt;链路输出速率。</p><p><strong>网络核心的关键功能</strong></p><p>（1）路由：决定分组采用的源到目标的路径。</p><p>（2）转发：将分组从路由器的输入链路转移到输出链路。</p><h2 id="1-4-接入网和物理媒体"><a href="#1-4-接入网和物理媒体" class="headerlink" title="1.4 接入网和物理媒体"></a>1.4 接入网和物理媒体</h2><h3 id="1-4-1-接入网"><a href="#1-4-1-接入网" class="headerlink" title="1.4.1 接入网"></a>1.4.1 接入网</h3><h4 id="1、住宅接入：modem"><a href="#1、住宅接入：modem" class="headerlink" title="1、住宅接入：modem"></a>1、住宅接入：modem</h4><p>将上网数据调制加载到音频信号上，在电话线上传输，在局端将其中的数据解调出来。</p><p>带宽很窄,不能同时上网和通话。</p><h4 id="2、接入网：DSL"><a href="#2、接入网：DSL" class="headerlink" title="2、接入网：DSL"></a>2、接入网：DSL</h4><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220207133300830.png" alt="image-20220207133300830"></p><p>0~4kHz仍作音频传输，高于4k的一部分作下行，一部分作上行，使用额外的带宽，仍然采用调制和解调的方式。</p><h4 id="3、接入网：线缆网络"><a href="#3、接入网：线缆网络" class="headerlink" title="3、接入网：线缆网络"></a>3、接入网：线缆网络</h4><p>把有线电视信号线缆双向改造，在不同频段传输不同信道的数据。</p><p>线缆和光纤网路将各个家庭用户接入到ISP路由器。与DSL不同，各用户共享上行带宽。</p><h4 id="4、接入网：家庭网络"><a href="#4、接入网：家庭网络" class="headerlink" title="4、接入网：家庭网络"></a>4、接入网：家庭网络</h4><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220207134156849.png" alt="image-20220207134156849"></p><h4 id="5、企业接入网络"><a href="#5、企业接入网络" class="headerlink" title="5、企业接入网络"></a>5、企业接入网络</h4><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220207134345428.png" alt="image-20220207134345428"></p><p>通过交换机的集联。</p><h4 id="6、无线接入网络"><a href="#6、无线接入网络" class="headerlink" title="6、无线接入网络"></a>6、无线接入网络</h4><p>各无线端系统共享无线接入网络（端系统到路由器），通过无线LAN或广域无线接入的方式。</p><h3 id="1-4-2-物理媒体"><a href="#1-4-2-物理媒体" class="headerlink" title="1.4.2 物理媒体"></a>1.4.2 物理媒体</h3><p>物理链路：在每个传输-接收对，跨越一种物理媒体的介质。</p><p>导引型媒体：信号沿着固体媒介被导引，如同轴电缆、光纤、双绞线。非导引型媒体是信号自由传输。</p><p>无线链路：开放空间传输电磁波。无需物理线缆。</p><h2 id="1-5-Internet结构和ISP"><a href="#1-5-Internet结构和ISP" class="headerlink" title="1.5 Internet结构和ISP"></a>1.5 Internet结构和ISP</h2><p>互联网结构是网络的网络，端系统通过<strong>接入ISPs</strong>接到互联网。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220215122033621.png" alt="image-20220215122033621"></p><p>然后内容提供商网络ICP可能会构建自己的网络（靠近ISP），将自己的服务、内容更加靠近用户，减少自己支出。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220215124059819.png" alt="image-20220215124059819"></p><p><strong>第一层ISP</strong>完成全球的国家/国际覆盖，点很少，速率极高。它们之间直接或通过IXP连接，并与大量的第二层ISP和其他客户网相连。</p><p><strong>第二层ISP</strong>（包括更小的区域ISP），与一个或多个第一层ISPs相连，也可能与第二层ISP相连。</p><p>终端通过local ISP、第三层、第二层、第一层ISP接入互联网。</p><h2 id="1-7-协议层次和服务模型"><a href="#1-7-协议层次和服务模型" class="headerlink" title="1.7  协议层次和服务模型"></a>1.7  协议层次和服务模型</h2><p>将网络的复杂功能分层，每层实现一组功能：本层协议实体交互执行本层的协议动作，通过接口访问下层的提供的服务，来实现本层的功能。</p><p><strong>协议</strong>：本层协议实体交互的应该遵守的协议动作的集合。</p><p><strong>数据单元DU：</strong>上层的服务数据单元SDU传给下层，加上一个头部封装成这一层的协议数据单元PDU。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220215174311868.png" alt="image-20220215174311868"></p><p><strong>服务</strong>：低层实体向上层实体提供它们之间的通信的能力。服务访问点SAP用来区分上层不同服务用户的信息。</p><p>本层提供的服务不仅包括所有下层提供的服务，还包括同层之间通过接口实现的新的服务特性（可以向上层提供的服务）。</p><p><strong>原语</strong>：上层使用下层服务的形式，即提供什么类型的服务（面向连接的或无连接的）。</p><p><strong>Internet协议栈</strong></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220215175055180.png" alt="image-20220215175055180"></p><p><strong>传输层</strong>：在网络层主机到主机传输基础之上的进程到进程的区分数据传输；可靠。</p><p><strong>网络层</strong>：在链路层基础上，传输以分组为单位的端到端的数据；不可靠。</p><p><strong>链路层</strong>：以帧frame为单位，把bit组合根据帧头帧尾区分出一帧一帧，在<strong>相邻</strong>网点之间传送数据。</p><p><strong>各层次的协议数据单元：</strong></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220215191048948.png" alt="image-20220215191048948"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Deep learning学习笔记</title>
      <link href="/2022/01/23/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/abstrac%20of%20machine-learning/"/>
      <url>/2022/01/23/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/abstrac%20of%20machine-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="Deep-learning-——李宏毅"><a href="#Deep-learning-——李宏毅" class="headerlink" title="Deep learning                 ——李宏毅"></a>Deep learning                 ——李宏毅</h1><p>Machine-learning ≈looking for function</p><h2 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h2><p>regression: outputs a scalar;</p><p>classification;</p><p>structed learning: 授人予渔；</p><h2 id="How？"><a href="#How？" class="headerlink" title="How？"></a>How？</h2><p>step1.function with unknown paraments(based on domain knowledge): 写出带有未知参数（weight 和bias）的函数。</p><p>step2.Define Loss(how good a set of value is) from Traning Data: L(b,w) ：lable；</p><p>step3.Optimization</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116152841457.png" alt="image-20220116152841457"></p><p>Gradient Descent的方法就是先对一个参数来说，随机在w0的位置求L对w的微分，选择increase或作者decrease。</p><p>![image-20220116153237304](C:\Users\Aucuba\Pictures\upload\Deep learning\image-20220116153237304.png)</p><p>移动的步长，可以根据斜率和learning rate参数(hyperparaments,自己设定的参数)来确定。</p><p>使用Gradient Descent的方法会造成local minima（局部最小）而不是global minima 的问题，但这在真正的工作中并不是真正让人头痛的问题。</p><h3 id="Advanced-step1"><a href="#Advanced-step1" class="headerlink" title="Advanced step1"></a>Advanced step1</h3><p>纯线性的函数并不符合实际问题的要求，比如下图红色分段线性曲线。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116160105957.png" alt="image-20220116160105957"></p><p>可以用上图多个分段线性的蓝色曲线来逼近真正的圆滑曲线。而上图蓝色的分段函数曲线（它的名字其实是hard sigmod）就可以用不同的sigmod函数逼近（改变参数b、w、c)：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116155834145.png" alt="image-20220116155834145"></p><p>以3个（自己决定）sigmod为例，拓展到神经网络(Neuron Network)：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116160856166.png" alt="image-20220116160856166"></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116161314702.png" alt="image-20220116161314702"></p><p>所有的参数用一个符号表示：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116161649422.png" alt="image-20220116161649422"></p><p>同理可以选择其他的函数代替sigmod逼近，比如ReLu：<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116163906744.png" alt="image-20220116163906744">这种函数我们叫激活函数。</p><p>用更多层的模型来训练，更好地逼近真实, many layers = deep -&gt; deeo learning 。</p><p>但是更多层不意味着一定会更好地拟合真实，甚至会出现overfitting的情况。</p><h3 id="Advanced-step2-amp-step3"><a href="#Advanced-step2-amp-step3" class="headerlink" title="Advanced step2 &amp; step3"></a>Advanced step2 &amp; step3</h3><p>在Loss的计算上，推广到以θ为变量就可以了：Loss of θ；</p><p>在optimization上，同理随机选择θ0，然后偏移寻找：<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116162528315.png" alt="image-20220116162528315"></p><p>在真实工作中，把N笔资料随机分为一批批的batch，只用一组batch来计算Loss，每一组中更新参数叫update。把所有的batch全看过一遍叫做epoch。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20220116163423576.png" alt="image-20220116163423576"></p><h2 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络 CNN"></a>卷积神经网络 CNN</h2><p>designed for image</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文笔记—Universal Deep Hiding for Steganography,Watermarking, and Light Field Messaging</title>
      <link href="/2021/12/26/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/UDH/"/>
      <url>/2021/12/26/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/UDH/</url>
      
        <content type="html"><![CDATA[<h1 id="UDH-Universal-Deep-Hiding-for-Steganography-Watermarking-and-Light-Field-Messaging"><a href="#UDH-Universal-Deep-Hiding-for-Steganography-Watermarking-and-Light-Field-Messaging" class="headerlink" title="UDH: Universal Deep Hiding for Steganography,Watermarking, and Light Field Messaging"></a>UDH: Universal Deep Hiding for Steganography,Watermarking, and Light Field Messaging</h1><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>​        传统的隐写技术通常需要对秘密信息进行完美地编码，才能保证不被隐写分析所发现。相反地，另一种隐写技术（被称为深度隐写术）放宽了对完美编码的限制，在专注于大隐藏容量的同时，还能保证视觉质量。</p><p>该论文的工作是解释深度隐写术的工作原理，并研究其在水印和LFM中的应用。</p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211210101105302.png" alt="image-20211210101105302" style="zoom:80%;" /><p>​        现有的深度隐藏：依赖覆盖的深度隐藏（DDH)。C和（S processed，被处理过的S）作为网络H的输入，生成C’，再利用恢复网络R恢复秘密信息得到S‘。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212115522165.png" alt="image-20211212115522165"></p><p>​        通用深度隐藏UDH：以不可知的方式隐藏图像，没有依赖性。</p><h3 id="最初的猜测"><a href="#最初的猜测" class="headerlink" title="最初的猜测"></a>最初的猜测</h3><p>​        一种自然地猜测是LSB，隐藏在最低有效位中，但是另一篇论文【Shumeet Baluja. Hiding images in plain sight: Deep steganography. InAdvances in Neural Information<br>Processing Systems (NeurIPS), 2017】中的分析否定了这种猜测。</p><h3 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h3><p>​        发现UDH的成功可以直接归因于Se（||C’-C||)和C之间的频率差异。通过DDH和UDH的H和R交叉测试，我们也成功地证明了DDH的工作原理。</p><p>​        与通过隐藏二进制信息来进行水印的HiDDeN相比，我们第一个通过隐藏图像来演示(基于dnn的)水印。用于隐藏图像的UDH无需再训练就可以很容易地扩展到隐藏简单的二进制信息，实现优越的性能。UDH对C’上的像素强度偏移具有较强的鲁棒性，这使得它更适合于LFM任务，UDH是第一个成功隐藏和传输对光线效果不敏感的图像的技术，增加了它在现实世界的适用性。还值得一提的是，UDH不需要收集大型screen-pair数据集(1.9TB)。对于传输简单的二进制信息，UDH也实现了更好的性能。</p><h2 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2  Related work"></a>2  Related work</h2><p>​        工作重点是理解和利用深度学习来隐藏图像中的信息。</p><h4 id="图片中隐藏二进制信息"><a href="#图片中隐藏二进制信息" class="headerlink" title="图片中隐藏二进制信息"></a>图片中隐藏二进制信息</h4><p>​        DNN在广泛的应用领域取得了成功，如隐写术和水印。其中,HiDDeN采用对抗性训练（adversarial training），以end-to-end的方式隐藏二进制信息，最大限度地减少人为对C’的影响。这些方法的性能通常会存在冲突，如高容量-保密性低等。</p><h4 id="图片中隐藏图片"><a href="#图片中隐藏图片" class="headerlink" title="图片中隐藏图片"></a>图片中隐藏图片</h4><p>​        DNN隐藏二进制信息的容量很低（&lt;0.5bpp）。在上文提到的论文中，深度隐写可以以24bpp容量隐藏完整图像。它采用额外的P网络将图像处理一种新形势。在现有工作的基础上，我们基于提出的UDN的元架构，解释深度隐写术的成功，并研究通用水印和LFM。</p><h2 id="3-Universal-deep-hiding-meta-architecture"><a href="#3-Universal-deep-hiding-meta-architecture" class="headerlink" title="3 Universal deep hiding meta-architecture"></a>3 Universal deep hiding meta-architecture</h2><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211210102950228.png" alt="image-20211210102950228" style="zoom:80%;" /><p>​        取随机C，S被送到H编码处理后生成Se添加到C得到C’，解密后S’与C影响不大。证明了通用性。</p><p>​        和universal attacks中，向随机图像添加UAP相似，但不同的是,H和R联合训练后产生的Se可以恢复R。loss函数定义为<img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212121635053.png" alt="image-20211212121635053"></p><h3 id="3-1-Basic-setup-and-results"><a href="#3-1-Basic-setup-and-results" class="headerlink" title="3.1  Basic setup and results"></a>3.1  Basic setup and results</h3><p>​        将H与R，同ADAM优化一起在ImageNet训练数据集，ADP（average pixel discrepancy）、PSNR（峰值信噪比）、SSIM（结构相似度）、LPIPS（感知相似度）表现如表：</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212122705025.png" alt="image-20211212122705025"></p><p>​        H采用简化的Cycle-GAN中的U-Net，R堆叠了几个卷积层。在H与R相同设置下进行实验，UDN与DDH实现了相当的性能，甚至更稳定。最终发现，H与R的架构选择对性能没有显著影响。通过设计，UDN不需要P，同时对于DDH，采用P甚至会破坏稳定性。我们的UDH定性结果如图（为更好地可视化，C与C’、S与S’的差异被放大）：</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212123746129.png" alt="image-20211212123746129"></p><h4 id="Remark-on-steganalysis"><a href="#Remark-on-steganalysis" class="headerlink" title="Remark on steganalysis"></a>Remark on steganalysis</h4><p>​        对UDH进行隐写分析，检测LSB的StegExpose被证明失败，但被训练作为DDN秘密信息检测的binary classifier成功检测了UDH隐藏信息的存在。论文的工作将提供直观的解释和从傅里叶的角度理解。</p><h2 id="4-Universal-Deep-Hiding-analysis"><a href="#4-Universal-Deep-Hiding-analysis" class="headerlink" title="4 Universal Deep Hiding analysis"></a>4 Universal Deep Hiding analysis</h2><h3 id="Where-is-the-secret-image-encoded"><a href="#Where-is-the-secret-image-encoded" class="headerlink" title="Where is the secret image encoded?"></a>Where is the secret image encoded?</h3><p>​        UDH管道执行两个映射H和R，来进行编码和解码。当S和S’的APD很小时，尤其是Se作为R的输入，解码过程可以看做编码的逆。接下来分析UDH在信道和空间维度的编码特性。</p><p>​        将Se和S’的信道宽分别设置为0来测量S和Se的通道效应。改变S中任何一个RGB信道，但Se所有三个信道中APD值仍相似，Se对S’的影响也镜像地相同。这表明编码和解码的映射不是基于信道的。</p><p>​        类似地我们研究空间维度，只将单个像素的像素强度设置为0，由于卷积操作的局部性质，推测只影响它周围的像素。观察到对于编码和解码，影响区域都很小。</p><h3 id="Se-visualization-and-Fourier-analysis"><a href="#Se-visualization-and-Fourier-analysis" class="headerlink" title="Se visualization and Fourier analysis"></a>Se visualization and Fourier analysis</h3><p>​        通过上述分析，秘密图像在信道中跨所有信道进行编码，在空间维中局部编码。然而，这仍然不足以理解深藏的成功。在图4中，我们放大Se并将其S中对应的内容可视化。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212131349380.png" alt="image-20211212131349380"></p><p>​        在原始图像S中，平滑区域的像素强度值是相同或非常相似的，但是在Se中对应的值与相邻的像素有很大的不同，参见上图的patch1或patch3。特别是Se清楚地显示了一种重复的高频(HF)特性，不同于以低频(LF)内容为主的自然图像。在提出的UDH中，覆盖图像C可以被认为是用来扰动Se的。有趣的是，解码可以在如此大的干扰下工作(注意覆盖图像C是随机选择的)。可视化结果直观解释了：R被隐式训练为只对HF内容敏感，在Se中为C添加LF几乎不破坏se的HF内容，因此C的干扰影响很有限。</p><p>​        进一步对自然图像和Se进行傅里叶分析，下图结果显示了C和Se之间明显的频率差异。每个网络在傅里叶空间中使用不同的高频区域，进一步说明频率差异是深度隐写成功的关键。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212132145814.png" alt="image-20211212132145814"></p><h3 id="Utilizing-UDH-to-help-visualizeSein-DDH"><a href="#Utilizing-UDH-to-help-visualizeSein-DDH" class="headerlink" title="Utilizing UDH to help visualizeSein DDH"></a>Utilizing UDH to help visualizeSein DDH</h3><p>​        Se拥有的高频内容使其对低频的C的干扰具有鲁棒性。对UDH和DDH和H和R进行交叉测试，一个元架构的H的输出被作为另一个元架构的R的输入，结果如图。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212132530162.png" alt="image-20211212132530162"></p><p>​        发现，在一些图像中仍然可以清晰地观察到S’，这表明DDH也用相同的方式进行编码。</p><p>​        为了进一步验证DDH的R也同样对高频内容进行解码来恢复秘密图像，过滤掉C’的高频内容，结果如图，秘密检索完全失败。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212142112978.png" alt="image-20211212142112978"></p><p>​        并发现Hu+Rd的组合中，放大观察到类似于上文的现象。说明编码解码方式类似。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212142341874.png" alt="image-20211212142341874"></p><h3 id="Comparison-of-DDH-and-UDH"><a href="#Comparison-of-DDH-and-UDH" class="headerlink" title="Comparison of DDH and UDH"></a>Comparison of DDH and UDH</h3><p>​        对自然图像，二者类似；当像素强度变化时就会出现差异。</p><p>​        DDH的优点是可以根据封面图像自适应编码秘密图像，对于普通图像，此属性不会导致显著的性能差异。然而对于HF含量高的内容，由于DDH框架的自适应特性，可以观察到DDH和UDH之间的性能差异。如左表所示，在向C添加严重均匀随机噪声的情况下，DDH仍然能够以低秘密APD恢复图像，但UDH会失败。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212142726049.png" alt="image-20211212142726049"></p><p>然而，DDH对噪声(HF)的鲁棒性是以对容器图像C’上像素强度偏移敏感为代价的。从右表的结果可以看出，当C’所有像素强度都平移50时，DDH几乎不能恢复秘密图像(APD:32.4)，而对UDH的影响是不可见的。这种差异可能由于设计的UDH框架对LF覆盖图像的干扰具有鲁棒性，也因此UDH这种对C’上像素强度偏移的鲁棒性使其适合于LFM的应用（因为一般来说，光的变化是平滑的）。</p><h2 id="5-Universal-Deep-Hiding-applications"><a href="#5-Universal-Deep-Hiding-applications" class="headerlink" title="5  Universal Deep Hiding applications"></a>5  Universal Deep Hiding applications</h2><p>​        以隐藏完整图像为重点，将UDH应用于隐写、水印和LFM。其中，隐写侧重高隐藏容量，水印侧重对于扭曲的鲁棒性，LFM侧重对光效应的鲁棒性。</p><h3 id="5-1-Universal-deep-steganography-beyond-hiding-one-image"><a href="#5-1-Universal-deep-steganography-beyond-hiding-one-image" class="headerlink" title="5.1 Universal deep steganography beyond hiding one image"></a>5.1 Universal deep steganography beyond hiding one image</h3><h4 id="Flexible-number-of-images-forSandC"><a href="#Flexible-number-of-images-forSandC" class="headerlink" title="Flexible number of images forSandC"></a>Flexible number of images forSandC</h4><p>​        S和C不需要拥有同数量的信道。可以让M个秘密信息隐藏到N个图片C中。虽然在复杂度增加时性能下降，但仍提高了灵活性。<img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212143634034.png" alt="image-20211212143634034"></p><h4 id="Different-recipients-get-different-secret-messages"><a href="#Different-recipients-get-different-secret-messages" class="headerlink" title="Different recipients get different secret messages"></a>Different recipients get different secret messages</h4><p>​        多个接受者从相同的C’中接收不同的S图片，我们训练三队H和R来对相应的秘密图像进行编码和解码，但将秘密图像隐藏在同一个C中，即C‘=C+Se1+Se2+Se3。同时也能保持相当的检索性能。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212143925952.png" alt="image-20211212143925952"></p><h3 id="5-2-Universal-deep-watermarking"><a href="#5-2-Universal-deep-watermarking" class="headerlink" title="5.2 Universal deep watermarking"></a>5.2 Universal deep watermarking</h3><p>​        HiDDeN已经探索了二进制信息的水印，我们分析了UDH对各种类型的图像畸变的鲁棒性，通过设计对Crop和Cropout具有鲁棒性，但是由于空间局部性质，我们只能显示隐藏在容器图像相应裁剪区域中的秘密图像。</p><h4 id="Watermarking-by-hiding-images"><a href="#Watermarking-by-hiding-images" class="headerlink" title="Watermarking by hiding images"></a>Watermarking by hiding images</h4><p>​        我们采用HiDDeN中相同的参数设置图像失真，评估如表。</p><p><img src="C:/Users/不息/AppData/Roaming/Typora/typora-user-images/image-20211212144237397.png" alt="image-20211212144237397"></p><h4 id="Watermarking-by-hiding-barcode"><a href="#Watermarking-by-hiding-barcode" class="headerlink" title="Watermarking by hiding barcode"></a>Watermarking by hiding barcode</h4><p>​        将高于128bit的像素强度设置为1，低于128bit设置为0，对空间维度的更好利用提高隐藏容量。</p><h3 id="5-3-Universal-photographic-steganography"><a href="#5-3-Universal-photographic-steganography" class="headerlink" title="5.3 Universal photographic steganography"></a>5.3 Universal photographic steganography</h3><p>​        摄影隐写术：图像显示在屏幕上，用相机捕捉。DDH因为对于像素强度的偏移不具有鲁棒性，所以需要额外训练一个相机-显示器转换函数来处理光场转换的失真，但UDH可以不需要训练。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文笔记—Attention Based Data Hiding with Generative Adversarial Networks</title>
      <link href="/2021/12/25/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ABDHwGAN/"/>
      <url>/2021/12/25/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ABDHwGAN/</url>
      
        <content type="html"><![CDATA[<h1 id="Attention-Based-Data-Hiding-with-Generative-Adversarial-Networks"><a href="#Attention-Based-Data-Hiding-with-Generative-Adversarial-Networks" class="headerlink" title="Attention Based Data Hiding with Generative Adversarial Networks"></a>Attention Based Data Hiding with Generative Adversarial Networks</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>论文提出了基于生成对抗网络GAN的ABDH框架，引导ABDH找到隐藏图像中不明显的区域，以端到端的方式稳健地隐藏数据。</p><h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="隐写术"><a href="#隐写术" class="headerlink" title="隐写术"></a>隐写术</h3><p>1、最低有效位隐写：LSB。</p><p>2、内容自适应隐写：手工制作变形函数来选择嵌入图像的定位。</p><p>3、基于深度学习的隐写：如基于深度卷积GAN、HiDDeN等。</p><h3 id="水印"><a href="#水印" class="headerlink" title="水印"></a>水印</h3><p>1、空间域水印：在像素域进行水印，复杂度低、成本低、延迟低。可以利用LSB水印方法。</p><p>2、光谱域水印：在空间域不易察觉。通过各种变换域技术实现，通常使用离散余弦变换DCT；也可使用小波变换将图像和水印分解为低频和高频，将水印嵌入到低频子带中，具有更好的隐蔽性和鲁棒性。</p><p>3、基于神经网络的水印。如基于神经网络的盲水印、基于长短期记忆结构的动态水印深度学习。</p><h2 id="Attention-Based-Data-Hiding"><a href="#Attention-Based-Data-Hiding" class="headerlink" title="Attention Based Data Hiding"></a>Attention Based Data Hiding</h2><h3 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h3><p><strong>GAN</strong>由生成模型和判别模型组成。生成模型是为了生成与真实样本非常相似的新样本，视图混淆判别器。判别模型会估计特定样本来自生成模型而不是真实样本的概率。当GAN模型达到纳什均衡时，判别模型对每对真实和生成的样本都返回0.5的分类概率，认为该模型训练良好。</p><p><strong>ABDH</strong>将数据隐藏的目标与<strong>GAN</strong>相结合。它由目标生成模型和隐藏数据判别模型组成。目标模型是为了生成与cover非常相似的目标图像，视图混淆判别模型；判别模型是为了将目标图像与覆盖图像区分开来。我们要训练一个数据隐藏的算法，让生成模型达到纳什均衡时（即生成模型可以使秘密信息在目标图像中保持不被察觉），同时隐藏数据判别模型对每对目标和掩蔽图像都不能检测到秘密信息的存在，这个模型收敛。</p><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225160747649.png" alt="image-20211225160747649"></p><p>1、原始的图像集cover经过Attention Model Ga（使用的是ResNet50特征提取骨干），产生Attention Mask（我们引入Attention Mask来帮助ABDH来明确学习cover的特征）。CI=cover Image。AM的每个值代表cover每个像素的“注意敏感度”，取值范围为0 ~ 1。如果该值更接近1，表示对应像素的变化会导致明显的差异，容易引起视觉检测的注意：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225161355634.png" alt="image-20211225161355634"></p><p>2、生成AM后，原始cover图像、AM和原始秘密图像(SI)经过目标图像生成模型GTI，生成目标图像 (TI):</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225161802290.png" alt="image-20211225161802290"></p><p>3、TI通过秘密图像生成模型GSI提取出秘密图像ESI：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225161925635.png" alt="image-20211225161925635"></p><p>4、cover image 判别模型DCI确保CI和TI的不可区分。</p><p>5、为了细化提取过程，保证原秘密图像与提取出的秘密图像不可区分，引入秘密图像循环判别模型DSI：<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225162500910.png" alt="image-20211225162500910"></p><p>即<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225162518531.png" alt="image-20211225162518531"></p><p>6、为保证秘密图像只能从目标图像中提取，而不能从原始cover中提取，引入额外的不一致loss：!<img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225162712548.png" alt="image-20211225162712548"></p><h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>ABDH总体的loss由三部分组成：对抗性损失<strong>LGAN(GTI,DCI)<strong>、循环对抗损失</strong>LGAN(GSI,DSI)<strong>、不一致的损失</strong>LIC</strong>。λ为调整对抗性损失与不一致损失百分比的参数，总的损失函数：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225163001090.png" alt="image-20211225163001090"></p><p>且不一致的损耗需要更改为最小化格式：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225163110664.png" alt="image-20211225163110664"></p><p>我们采用PSNR（评估灰度保真度）和SSIM（评估结构保真度）作为评判指标：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225163225423-16404211464021.png" alt="image-20211225163225423-16404211464021"></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225163240195.png" alt="image-20211225163240195"></p><h3 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h3><p><strong>目标图像生成模型GTI</strong>：一个卷积层（kernel size=7,s=0,p=0)，两个卷积层（k=3, s= 2, p = 1), 九个residual blocks残缺块 ,两个deconvolution layers反褶积层 (k= 3, s= 2, p=1, outside pad = 1), and 一个卷积层 (k=7, s=0, p=0)。每个卷积层和反褶积层后都跟着一个规范化实例层和一个ReLu层。</p><p><strong>秘密图像生成模型GSI</strong>的结构与GTI完全相同。</p><p><strong>覆盖图像判别模型DCI</strong>的网络结构与PatchGAN模型相似。每次它都会操作一个70×70的图像补丁，对该补丁的真伪进行分类。该模型将在整个图像中运行，并对70×70重叠补丁中的所有结果进行平均化，提供整体输出。DCI包含一个卷积层(k = 4,s = 2, p = 1)，跟随一个leaky ReLU层,三个卷积层(k = 4，s = 2, p = 1)，跟随一个规范化实例层和一个leaky ReLU层,一个卷积层(k = 4， s = 1, p = 1)，跟随一个规范化实例层和leaky ReLU层,一个卷积(k = 4,s = 1, p = 1),跟随一个sigmoid层。</p><p><strong>秘密图像周期判别模型DSI</strong>的结构与DCI一致。</p><p>为了提高收敛性能，使用Adam，而不是随机梯度下降SGD进行优化。Adam的参数为β1=0.5,β2=0.999。基本学习率 0.0002。</p><h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><p>训练中，实验应用了COCO数据集。以8:2的比例随机分割COCO，生成单独的训练和验证数据集。在训练数据集中，随机选择50%作为掩蔽图像，50%作为秘密图像。为了提高对攻击的鲁棒性，还生成了与原始训练数据集数目相同的被攻击训练数据集。从原始的训练数据集中，随机选取样本，分别加入各种噪声、滤波器、随机裁剪、随机移位和JPEG压缩。实验以PyTorch为框架，用150个epoch训练ABDH。损耗调节参数λ设为0.6。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225165343664.png" alt="image-20211225165343664"></p><p>第一行是cover。第二行是AM，红色代表敏感度高的区域。第三行是生成的目标图像，第四行是cover与TI的残差，第五行是提取的秘密图像，第六行是原始秘密图像与提取秘密图像的残差。</p><p>TI的评价指标如下表，说明隐藏的质量很高：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225170756910.png" alt="image-20211225170756910"></p><p>让我进一步分析，放大看残差会发现残差主要出现在物体的边缘和纹理部分。比如莉娜的帽子，F16飞机的边缘，狒狒的皮肤和胡须，水果和辣椒的轮廓等。这意味着在原始的封面图像中，<strong>ABDH</strong>倾向于将秘密信息隐藏在物体的边缘部分。在信息论中，纹理和边缘代表图像的高频部分，平滑区域代表图像的低频部分。如果我们改变低频部分就很容易被检测到。因此，目前许多最先进的算法都是将覆盖图像从空间域变换到频域，改变高频部分中的微小部分，并将其转换回空间域。从学习过程来看，<strong>ABDH</strong>检测器的生成网络对低频部分非常敏感，对高频部分不那么敏感。因此，ABDH生成的目标图像主要将其秘密信息隐藏在边缘和纹理部分，以保证最佳的隐蔽性。</p><p>ESI的评价指标说明恢复质量也很高：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225171313871.png" alt="image-20211225171313871"></p><h3 id="Quantitative-Comparative-Experiments"><a href="#Quantitative-Comparative-Experiments" class="headerlink" title="Quantitative Comparative Experiments"></a>Quantitative Comparative Experiments</h3><p>与LSB、内容自适应隐写、空间域水印、深度学习水印对比。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225174118424.png" alt="image-20211225174118424"></p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225174147619.png" alt="image-20211225174147619"></p><p>根据这些指标，ABDH的表现和鲁棒性由于其他所有的算法。进一步分析，发现基于深度学习的方法的性能并没有预期那么好。对于SSGAN，它的重点是生成新的cover图像。但在我们的实验中，cover图像是固定的。对于HiDDeN，每像素可隐藏的位非常低，不适合整个图像的嵌入。对于ISGAN算法，其固有的局限性是当目标图像受到噪声攻击时，秘密图像会有损耗。因此，深度学习隐写方法的性能仅与LSB隐写方法处于同一水平，不如内容自适应隐写方法。</p><h3 id="Ablation-Experiments"><a href="#Ablation-Experiments" class="headerlink" title="Ablation Experiments"></a>Ablation Experiments</h3><p>通过消融实验，找出了实验模型的三个关键特征：</p><p>1、循环判别模型的引入。2、额外不一致损失的引入。3、注意模型attention model的引入。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225174725134.png" alt="image-20211225174725134"></p><h3 id="Influence-of-Secret-Embedding-Amount"><a href="#Influence-of-Secret-Embedding-Amount" class="headerlink" title="Influence of Secret Embedding Amount"></a>Influence of Secret Embedding Amount</h3><p>随着隐藏信息容量的增加，鲁棒性减弱。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>论文笔记—HiDDeN,Hiding Data With Deep Networks</title>
      <link href="/2021/12/25/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/HiDDeN%20Hiding%20Data%20With%20Deep%20Networks/"/>
      <url>/2021/12/25/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/HiDDeN%20Hiding%20Data%20With%20Deep%20Networks/</url>
      
        <content type="html"><![CDATA[<h1 id="HiDDeN-Hiding-Data-With-Deep-Networks"><a href="#HiDDeN-Hiding-Data-With-Deep-Networks" class="headerlink" title="HiDDeN: Hiding Data With Deep Networks"></a>HiDDeN: Hiding Data With Deep Networks</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>使用神经网络端到端训练开发一个在图像中隐藏数据的框架。与传统的数据隐藏方法相比，我们的方法可以通过在训练时改变参数或噪声层，灵活地在容量、保密性和对不同类型噪声的鲁棒性之间进行权衡。HiDDeN这样的端到端方法在鲁棒数据隐藏方面具有根本优势:新的失真可以直接纳入训练过程，而不需要设计新的、专门的算法。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>隐写分析：第三方攻击者检测编码图片的工作。</p><p>数字水印的目标：Alice编码，Eve扭曲图像，Bob仍能检测出信息——鲁棒性。</p><p>数字水印的应用：即使Alice的图像发布后被修改，也能证明图像的所有权。更侧重鲁棒性而不是保密性。</p><p>HiDDeN：可应用于隐写和水印的end-to-end的可训练数据隐藏框架。使用三个卷积神经网络：编码网络接收cover 图片和信息（a bit string），并输出为编码图像；解码网络接收图像并重建信息；第三种攻击网络预测给定图像是否包含编码消息，这提供了一种对抗loss，提高了编码图像的质量。为模拟现实世界对图像的扭曲，在编码器和解码器间插入可选噪声层。</p><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><p>blind menthods与我们的工作相关，它是指解码器不假定能够访问cover图像。所以我们用神经网络对数据隐藏管道建模，进行端到端的训练，并使用bilnd的方法（不需要接收者访问图像）。另外，比LSB更具有鲁棒性的编码方式是在频率域，或者将频域编码与对数极坐标映射或模板匹配相结合，以实现对空间域变换的鲁棒性。</p><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3 Method"></a>3 Method</h2><h3 id="组成部件"><a href="#组成部件" class="headerlink" title="组成部件"></a>组成部件</h3><p><strong>编码器</strong>：Eθ （角标是参数）。编码器接收一个C×H×W大小的cover图片Ico，和长L的二进制信息Min，产生一个和Ico相同规模的已编码图像Ien。</p><p><strong>无参数噪声层</strong>：N。接收输入的图像并将编码后的图像失真以产生噪声图像Ino。</p><p><strong>解码器</strong>：Dφ。从Ino中恢复图像Mout</p><p><strong>反对抗鉴别器</strong>：Aγ。对于给定的图片（cover或encoded），辨别是否含有隐藏信息。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225123000325.png" alt="image-20211225123000325"></p><p><strong>编码器</strong>对cover图片进行卷积形成中间表示，并在空间上复制message信息并连接到编码器的中间，确保下一层的每一个卷积核都能访问整个消息。经过多层的卷积后，编码器产生编码图像。</p><p><strong>噪声层</strong>添加噪声，不要求Ino与Ien的尺寸相同，所以可以用裁剪等改变尺寸的方式进行处理。</p><p><strong>解码器</strong>首先应用几个卷积层在中间表示中形成L特征通道，然后应用全局空间平均池（确保在不同的空间维度上处理输入）生成与消息大小L相同的向量，最后应用一个现行层来生成预测的信息。</p><p><strong>对抗者</strong>有一个类似解码器的结构，但最后输出一个二分类。</p><p>通过改变组成部件的参数，可以训练其适应隐写和水印。</p><h3 id="如何描述工作的好坏"><a href="#如何描述工作的好坏" class="headerlink" title="如何描述工作的好坏"></a>如何描述工作的好坏</h3><p>1、<strong>image distortion loss</strong>：描述已编码图像与原cover图像相比的失真度。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225122232982.png" alt="image-20211225122232982"></p><p>2、<strong>adversarial loss</strong>：鉴别器检测编码图像Ien的能力。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225122300509.png" alt="image-20211225122300509"></p><p>3、鉴别器因其预测而导致<strong>分类损失</strong>：</p><p>![image-20211225122424961](C:\Users\Aucuba\Pictures\upload\HiDDeN Hiding Data With Deep Networks\image-20211225122424961.png)</p><p>4、<strong>message distortion</strong>：解码器获得的信息与原信息相比的失真度。</p><p>5、对θ， φ进行随机梯度下降，使<strong>loss损失</strong>最小（λ1和λ2控制损失的相对重量）：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225122512010.png" alt="image-20211225122512010"></p><p>6、同时训练反对抗鉴别器的参数γ，使同一分布上的后续<strong>loss损失</strong>最小：</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225122649109.png" alt="image-20211225122649109"></p><h3 id="噪声层"><a href="#噪声层" class="headerlink" title="噪声层"></a>噪声层</h3><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225124504847.png" alt="image-20211225124504847"></p><p>考虑到要在各种图像畸变下具有鲁棒性，实验了六种不同类型的噪声层。</p><p><strong>Dropout</strong>和<strong>Cropout</strong>撤销了编码器的一些更改，通过将cover图像和编码图像组合在一起生成噪声图像。他们都保留了编码图像不同百分比p的像素，但<strong>Dropout</strong>独立地选择每个像素，<strong>Cropout</strong>是随机裁剪的。</p><p><strong>Gaussian</strong>采用宽度σ的高斯核模糊编码图像。</p><p><strong>Crop</strong>随机将编码图像裁剪一个H’×W’的正方形。</p><p><strong>JPEG</strong>应用质量因子（1~100）来压缩图像。 </p><p>其中，<strong>Dropout</strong>、<strong>Crop</strong>和<strong>Cropout</strong>主要影响空间域，而<strong>Gaussian</strong>和<strong>JPEG</strong>作用于频域。</p><p><strong>JPEG- mask</strong>和<strong>JPEG- drop</strong>是JPEG压缩的可微分近似。采用可微分近似，可以不需要保证噪声是可微的。JPEG压缩将图像划分为8×8个区域，在每个区域内计算离散余弦变换(DCT)，然后将得到的频域系数量化为不同的粗度。量化步骤是不可微的，所以JPEG压缩不适用于基于梯度的优化。然而，将一个值量化就是信息——从理论上讲，这相当于限制了可以通过该“通道”传输的信息量。为了限制通过特定频域信道传递的信息量，我们创建了模拟JPEG压缩的噪声层。这些层使用8×8的步长为8的卷积层进行DCT变换，每个滤波器对应于DCT变换中的一个基向量。因此，网络激活表示编码图像的DCT域系数，然后对DCT系数使用<strong>Masking</strong>/<strong>Dropout</strong>来限制信息流;频率越高的系数越容易被屏蔽/丢弃，如图。然后使用转置卷积来实现DCT逆变换，得到噪声图。</p><p><img src="https://gitee.com/aucuba/my_blogs/raw/master/_pictures/image-20211225130947311.png" alt="image-20211225130947311"></p><p><strong>JPEG- mask</strong>采用固定的遮蔽，在Y通道中只保留25个低频DCT系数，在U、V通道中保留9个，其他系数设为零。<strong>JPEG-Drop</strong>在系数上应用渐进式删除。这两种方法都成功地生成了对实际JPEG压缩具有鲁棒性的模型。</p><h2 id="4-Experiment"><a href="#4-Experiment" class="headerlink" title="4 Experiment"></a>4 Experiment</h2><p>评估模型：<strong>容量</strong>、<strong>保密性</strong>、<strong>鲁棒性</strong>。</p><p>每像素位BBP度量<strong>容量</strong>；训练一个隐写分析器用于检测，它的测试精度就是检测率，用它衡量<strong>保密性</strong>；峰值信噪比PSNR测量图像失真，比特精度（输入信息和预测信息的相同比特数）衡量<strong>鲁棒性</strong>。它们之间有的具有竞争关系。</p><h3 id="4-1-隐写术：容量和保密性"><a href="#4-1-隐写术：容量和保密性" class="headerlink" title="4.1 隐写术：容量和保密性"></a>4.1 隐写术：容量和保密性</h3><p>训练模型在尺寸16×16的灰度图像中编码L= 52的二进制信息，使训练的模型的容量为52/(16×16)≈0.203 BPP。对于较大的图像使用较长的消息来保留编码容量。实验模型在图像的每个16×16补丁上编码一个L位的消息块,而隐写术通常假设无噪声传输，所以设置N为身份层。</p><h3 id="4-2-数字水印：鲁棒性"><a href="#4-2-数字水印：鲁棒性" class="headerlink" title="4.2 数字水印：鲁棒性"></a>4.2 数字水印：鲁棒性</h3><p>通过实验中改变失真的类型，学习不同失真下的鲁棒性。实验在YUV彩色图像C×H×W= 3×128×128上训练模型，信息长度为30，权重因子λ i = 0.7， λ g = 0.001。模型以恒等噪声层作为参考进行训练。在训练时间内，采用不同的噪声层对6种模型进行训练:Dropout (p= 0.3)、Cropout (p= 0.3)、Crop (p= 0.035)、Gaussian (σ= 2.0)、JPEG-mask和JPEGdrop。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
